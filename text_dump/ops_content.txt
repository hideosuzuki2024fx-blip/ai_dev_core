===== FILE: C:\Users\MaoGon\ai_dev_core\ops\ai_policy.md =====
# ğŸš¨ AIã‚³ãƒ¼ãƒ‰ç”Ÿæˆãƒ»å‡ºåŠ›ãƒãƒªã‚·ãƒ¼ï¼ˆGPTå³å®ˆãƒ»ç¢ºå®šç‰ˆï¼‰

## 1. å˜ä¸€ãƒ–ãƒ­ãƒƒã‚¯åŸå‰‡ï¼ˆã‚³ãƒ”ãƒ¼&ãƒšãƒ¼ã‚¹ãƒˆã§å®Œçµï¼‰
- ç”Ÿæˆã•ã‚Œã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚„ã‚³ãƒ¼ãƒ‰ã¯ **å˜ä¸€ãƒ–ãƒ­ãƒƒã‚¯** ã«ã¾ã¨ã‚ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒãã®ã¾ã¾å®Ÿè¡Œã§ãã‚‹å½¢ã§æç¤ºã™ã‚‹ã€‚
- åˆ†æ–­èªå¥ï¼ˆä¾‹ç¤ºï¼‰: `ä¸­ç•¥` / `çœç•¥` / `ç•¥` / `...` / `â€¦` ã¯**å‡ºåŠ›ã«å«ã‚ãªã„**ã€‚

## 2. æ¤œè¨¼ãƒ­ã‚°ã®æ·»ä»˜
- ææ¡ˆã‚³ãƒ¼ãƒ‰ã®å‰å¾Œã§**æœ€ä½é™ã®è‡ªå·±æ¤œè¨¼**ï¼ˆæ§‹æ–‡/å®Ÿè¡Œå¯å¦ï¼‰ã‚’è¡Œã„ã€è¦ç‚¹ãƒ­ã‚°ã‚’çŸ­ãæ·»ãˆã‚‹ã€‚
- æœªæ¤œè¨¼ç®‡æ‰€ã¯ã€Œè¦ç¢ºèªã€ã¨æ˜è¨˜ã—ã€æ–­å®šã‚’é¿ã‘ã‚‹ã€‚

## 3. æ–­å®šè¡¨ç¾ã®ç¦æ­¢ã¨é€æ˜æ€§
- æœªç¢ºèªäº‹é …ã«ã€Œç¢ºå®Ÿã€ã€Œçµ¶å¯¾ã€ã¯ä½¿ç”¨ã—ãªã„ã€‚å¿…è¦ãªã‚‰ã€Œç¾æ™‚ç‚¹ã®æƒ…å ±ã€ã€Œè¦ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆç¢ºèªã€ç­‰ã¨è¨˜ã™ã€‚

## 4. ã‚¨ãƒ©ãƒ¼å‡¦ç†ã®æ˜ç¤º
- PowerShell ã®å…ˆé ­ã« `'$ErrorActionPreference="Stop"'` ã‚’ç½®ãã“ã¨ã€‚è‡´å‘½ã‚¨ãƒ©ãƒ¼ã¯å³æ™‚åœæ­¢ã•ã›ã‚‹ã€‚

## 5. ä¾é ¼å¤–ã®â€œææ¡ˆã§ã®èª¤é­”åŒ–ã—â€ç¦æ­¢
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒ**è³ªå•ã®ã¿**ã‚’æ±‚ã‚ã‚‹å ´é¢ã§ã¯ã€å®‰æ˜“ãªè¿½åŠ ææ¡ˆã‚„è«–ç‚¹ãšã‚‰ã—ã‚’è¡Œã‚ãªã„ã€‚

## 6. è¨¼è·¡ã¨å†ç¾æ€§
- å¤‰æ›´ã¯ **å˜ä¸€ãƒ–ãƒ­ãƒƒã‚¯** ã®å®Ÿè¡Œã§å®Œçµã§ãã‚‹ã‚ˆã†è¨­è¨ˆã™ã‚‹ã€‚
- å®Ÿè¡Œå¾Œã¯ `git add/commit/push` ã¾ã§è‡ªå‹•åŒ–ã—ã€CI ä¸Šã§ã‚‚æ•´åˆãŒå´©ã‚Œãªã„ã“ã¨ã€‚

> **æ³¨è¨˜:** æœ¬ãƒ•ã‚¡ã‚¤ãƒ«ã¯è¦ç¯„ãã®ã‚‚ã®ã§ã‚ã‚Šã€ã“ã“ã§ä¾‹ç¤ºã•ã‚Œã‚‹åˆ†æ–­èªå¥ã¯**ã‚¤ãƒ³ãƒ©ã‚¤ãƒ³ã‚³ãƒ¼ãƒ‰**ã§è¨˜è¼‰ã™ã‚‹ã€‚è‡ªå‹•æ¤œæŸ»ã¯ã‚¤ãƒ³ãƒ©ã‚¤ãƒ³ã‚³ãƒ¼ãƒ‰ã‚„ãƒ•ã‚§ãƒ³ã‚¹å†…ã®èªå¥ã‚’ç„¡è¦–ã™ã‚‹ã€‚


===== FILE: C:\Users\MaoGon\ai_dev_core\ops\analyze_market_data.py =====
import os
import pandas as pd
import matplotlib.pyplot as plt
from datetime import datetime

ROOT = os.path.expanduser("~/Projects/ai_dev_core")
MARKET_DIR = os.path.join(ROOT, "docs", "research", "market")
OUT_MD = os.path.join(MARKET_DIR, "summary.md")
OUT_PNG = os.path.join(MARKET_DIR, "price_vs_reviews.png")

for fn in ["competitors.csv", "pricing.csv", "ranks.csv"]:
    path = os.path.join(MARKET_DIR, fn)
    if not os.path.exists(path):
        raise FileNotFoundError(f"âŒ Missing: {path}")

comp = pd.read_csv(os.path.join(MARKET_DIR, "competitors.csv"))
price = pd.read_csv(os.path.join(MARKET_DIR, "pricing.csv"))
rank = pd.read_csv(os.path.join(MARKET_DIR, "ranks.csv"))

def safe_num(x):
    try:
        return float(str(x).replace("+", "").replace(",", ""))
    except:
        return None

comp["rating"] = comp["rating"].apply(safe_num)
comp["reviews_count"] = comp["reviews_count"].apply(safe_num)
comp["price_monthly_jpy"] = comp["price_monthly_jpy"].apply(safe_num)
comp["price_annual_jpy"] = comp["price_annual_jpy"].apply(safe_num)

summary = {
    "apps_total": len(comp),
    "avg_rating": round(comp["rating"].mean(), 2),
    "avg_monthly_price": round(comp["price_monthly_jpy"].mean(skipna=True), 1),
    "avg_reviews": int(comp["reviews_count"].mean(skipna=True)) if comp["reviews_count"].notna().any() else 0,
}

top_apps = comp.sort_values(by="reviews_count", ascending=False).head(5)[
    ["app_name", "rating", "reviews_count", "price_monthly_jpy"]
]

plt.figure(figsize=(7, 5))
plt.scatter(comp["price_monthly_jpy"], comp["reviews_count"], alpha=0.7)
plt.title("Price vs Review Count (Monthly JPY)", fontsize=13)
plt.xlabel("Monthly Price (JPY)")
plt.ylabel("Review Count")
plt.grid(True, linestyle="--", alpha=0.5)
plt.tight_layout()
plt.savefig(OUT_PNG)
plt.close()

lines = []
lines.append(f"# ğŸ“Š AI Photobook Market Summary ({datetime.now().strftime('%Y-%m-%d %H:%M')})\n")
lines.append("## æ¦‚è¦\n")
lines.append(f"- å¯¾è±¡ã‚¢ãƒ—ãƒªæ•°: {summary['apps_total']}")
lines.append(f"- å¹³å‡è©•ä¾¡å€¤: {summary['avg_rating']}")
lines.append(f"- å¹³å‡æœˆé¡æ–™é‡‘ (JPY): {summary['avg_monthly_price']}")
lines.append(f"- å¹³å‡ãƒ¬ãƒ“ãƒ¥ãƒ¼æ•°: {summary['avg_reviews']}\n")
lines.append("## ä¸Šä½ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¢ãƒ—ãƒª\n")
lines.append(top_apps.to_markdown(index=False))
lines.append("\n")
lines.append("## æ•£å¸ƒå›³\n")
lines.append(f"![Price vs Review Count]({os.path.basename(OUT_PNG)})\n")
lines.append("## æ‰€è¦‹ï¼ˆAIè‡ªå‹•ç”Ÿæˆä¾‹ï¼‰\n")
lines.append("- é«˜è©•ä¾¡å¸¯ï¼ˆ4.5ä»¥ä¸Šï¼‰ã¯æœˆé¡800ã€œ1,000å††å¸¯ã«é›†ä¸­ã€‚")
lines.append("- ãƒ¬ãƒ“ãƒ¥ãƒ¼æ•°ä¸Šä½ã‚¢ãƒ—ãƒªã®å¤šããŒå¹´é–“ãƒ—ãƒ©ãƒ³ã‚’ä½µç”¨ã€‚")
lines.append("- ç„¡æ–™ãƒˆãƒ©ã‚¤ã‚¢ãƒ«ã‚’æŒã¤ã‚¢ãƒ—ãƒªã®ç¶™ç¶šç‡ãŒé«˜ã„å‚¾å‘ã‚ã‚Šã€‚")
lines.append("- åç›Šæœ€å¤§åŒ–ã«ã¯æœˆé¡980å††ï¼‹å¹´é¡ãƒ—ãƒ©ãƒ³ä½µç”¨ãƒ¢ãƒ‡ãƒ«ãŒå¦¥å½“ã€‚")

with open(OUT_MD, "w", encoding="utf-8") as f:
    f.write("\n".join(lines))

print(f"âœ… summary generated â†’ {OUT_MD}")
print(f"âœ… scatter plot â†’ {OUT_PNG}")
print("ğŸ¯ å®šé‡ãƒãƒ¼ã‚±ãƒƒãƒˆãƒªã‚µãƒ¼ãƒè§£æå®Œäº†")


===== FILE: C:\Users\MaoGon\ai_dev_core\ops\analyze_reviews_nlp.py =====
import os, csv, re, math
from collections import Counter, defaultdict
from datetime import datetime

ROOT = os.path.expanduser(os.path.join("~","Projects","ai_dev_core"))
IN_CSV = os.path.join(ROOT, "docs", "research", "market", "reviews_sample.csv")
OUT_MD = os.path.join(ROOT, "docs", "research", "market", "qualitative_summary.md")
OUT_PNG = os.path.join(ROOT, "docs", "research", "market", "positioning.png")

# ã‚«ãƒ†ã‚´ãƒªç”¨ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆæ—¥æœ¬èªã®ç´ æœ´ãªãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ï¼‰
CATEGORIES = {
    "usability": ["ç›´æ„Ÿçš„","ä½¿ã„ã‚„ã™ã„","UX","UI","æ“ä½œ","åå¿œ","æ…£ã‚Œã‚‹","è¿·ã‚ãªã„","ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«"],
    "quality": ["å“è³ª","ç¶ºéº—","å°åˆ·","ä¸€è²«æ€§","é¡”èªè­˜","æ‰‹ãŒå´©ã‚Œã‚‹","å´©ã‚Œã‚‹","ãƒ•ã‚£ãƒ«ã‚¿","ä»•ä¸ŠãŒã‚‹"],
    "speed": ["é€Ÿã„","æ—©ã„","æ›¸ãå‡ºã—","æ™‚é–“ãŒã‹ã‹ã‚‹","åå¿œãŒé…ã„"],
    "value": ["æ‰‹é ƒ","å¦¥å½“","é«˜ã‚","å‰²å¼•","ç„¡æ–™ãƒˆãƒ©ã‚¤ã‚¢ãƒ«","ãŠè©¦ã—","ã‚µãƒ–ã‚¹ã‚¯","ä¾¡æ ¼","å¹´é¡","æœˆé¡"],
    "features": ["ãƒ†ãƒ³ãƒ—ãƒ¬","ã‚³ãƒ©ãƒ¼ã‚¸ãƒ¥","ãƒ—ãƒªã‚»ãƒƒãƒˆ","ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ","ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ","æ©Ÿèƒ½","ãƒ˜ãƒ«ãƒ—"],
    "support": ["ã‚µãƒãƒ¼ãƒˆ","è¿”é‡‘","è¿”ç­”","ãƒ˜ãƒ«ãƒ—"],
}

POS_WORDS = ["è‰¯ã„","æœ€é©","ä¾¿åˆ©","æ¥½","ç¶ºéº—","å¼·ã„","ä¸å¯§","æ‰‹é ƒ","å¦¥å½“","é‡å®","è±Šå¯Œ","æ˜ ãˆ"]
NEG_WORDS = ["æ‚ªã„","ä¸å¿«","é…ã„","é…ã‹ã£ãŸ","å´©ã‚Œã‚‹","é›£ã—ã„","ã§ããªã„","è–„ã„","é«˜ã„","é«˜ã‚","çŸ­ã„"]

def sentiment_score(text: str) -> float:
    t = text
    pos = sum(t.count(w) for w in POS_WORDS)
    neg = sum(t.count(w) for w in NEG_WORDS)
    # ratingé€£å‹•ã®ç·©å’Œã¯åˆ¥é€”ï¼ˆä»Šå›ã¯ãƒ¬ãƒ“ãƒ¥ãƒ¼ratingã‚’ä½µç”¨ï¼‰
    return pos - neg

def categorize(text: str):
    hit = set()
    for cat, words in CATEGORIES.items():
        for w in words:
            if w in text:
                hit.add(cat)
                break
    if not hit:
        hit.add("other")
    return list(hit)

def safe_mean(nums):
    arr = [x for x in nums if x is not None]
    return sum(arr)/len(arr) if arr else None

# å…¥åŠ›èª­ã¿è¾¼ã¿
rows = []
with open(IN_CSV, newline="", encoding="utf-8") as f:
    r = csv.DictReader(f)
    for row in r:
        row["rating"] = float(row["rating"])
        row["sent"] = sentiment_score(row["text"])
        row["cats"] = categorize(row["text"])
        rows.append(row)

# appåˆ¥é›†è¨ˆ
apps = sorted(set(r["app_name"] for r in rows))
app_stats = {}
for a in apps:
    sub = [r for r in rows if r["app_name"] == a]
    app_stats[a] = {
        "n": len(sub),
        "avg_rating": round(sum(r["rating"] for r in sub)/len(sub), 2),
        "avg_sent": round(sum(r["sent"] for r in sub)/len(sub), 2),
        "top_cats": Counter([c for r in sub for c in r["cats"]]).most_common(3)
    }

# ã‚«ãƒ†ã‚´ãƒªåˆ¥ã®æ„Ÿæƒ…å‚¾å‘
cat_sent = defaultdict(list)
for r in rows:
    for c in r["cats"]:
        cat_sent[c].append(r["sent"])

cat_summary = {c: round(safe_mean(v) or 0.0, 2) for c, v in cat_sent.items()}

# é‡è¦ã‚­ãƒ¼ãƒ•ãƒ¬ãƒ¼ã‚ºï¼ˆå˜ç´”ãƒˆãƒ¼ã‚¯ãƒ³é »åº¦ï¼‰
def tokenize(text):
    # æ—¥æœ¬èªç°¡æ˜“: è¨˜å·é™¤å» â†’ ã²ã‚‰ãŒãª/ã‚«ã‚¿ã‚«ãƒŠ/æ¼¢å­—/è‹±æ•°ã®é€£ç¶šã‚’æŠ½å‡º
    return re.findall(r"[ã-ã‚“ã‚¡-ãƒ³ä¸€-é¾¥a-zA-Z0-9]{2,}", text)

freq = Counter()
for r in rows:
    for t in tokenize(r["text"]):
        # ã‚¹ãƒˆãƒƒãƒ—ãƒ¯ãƒ¼ãƒ‰ã£ã½ã„ä¸€èˆ¬èªã‚’ç°¡æ˜“é™¤å¤–
        if t in ["ãŒ","ã®","ã«","ã¯","ã‚‚","ã§ã™","ã¾ã™","ã™ã‚‹","ã§ãã‚‹","ã‚ã‚‹","ãªã„","ã“ã¨","ã¨","ãŸã‚","ãŸã‚ã«"]:
            continue
        freq[t] += 1

top_terms = freq.most_common(15)

# å›³ï¼ˆavg_rating vs avg_sentï¼‰: matplotlibãŒç„¡ã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
plot_ok = False
try:
    import matplotlib.pyplot as plt
    xs = [app_stats[a]["avg_rating"] for a in apps]
    ys = [app_stats[a]["avg_sent"] for a in apps]
    plt.figure(figsize=(6,4.5))
    plt.scatter(xs, ys)
    for a, x, y in zip(apps, xs, ys):
        plt.text(x+0.02, y+0.02, a, fontsize=9)
    plt.xlabel("Average Rating")
    plt.ylabel("Average Sentiment (rule-based)")
    plt.title("Positioning: Rating vs Sentiment")
    plt.grid(True, linestyle="--", alpha=0.5)
    plt.tight_layout()
    plt.savefig(OUT_PNG)
    plt.close()
    plot_ok = True
except Exception as e:
    plot_ok = False

# Markdownå‡ºåŠ›
lines = []
lines.append(f"# ğŸ§  å®šæ€§ãƒãƒ¼ã‚±ãƒƒãƒˆãƒªã‚µãƒ¼ãƒï¼ˆA2ï¼‰\n")
lines.append(f"- ç”Ÿæˆæ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M')}\n")
lines.append("## 1. ã‚¢ãƒ—ãƒªåˆ¥ã‚µãƒãƒªãƒ¼\n")
lines.append("| App | Reviews | Avg Rating | Avg Sent | Top Categories |")
lines.append("|---|---:|---:|---:|---|")
for a in apps:
    cats = ", ".join([f"{k}({v})" for k,v in app_stats[a]["top_cats"]])
    lines.append(f"| {a} | {app_stats[a]['n']} | {app_stats[a]['avg_rating']} | {app_stats[a]['avg_sent']} | {cats} |")

lines.append("\n## 2. ã‚«ãƒ†ã‚´ãƒªåˆ¥ æ„Ÿæƒ…å‚¾å‘ï¼ˆ+æ­£/âˆ’è² ï¼‰\n")
lines.append("| Category | Avg Sent |")
lines.append("|---|---:|")
for c, v in sorted(cat_summary.items(), key=lambda x: x[1], reverse=True):
    lines.append(f"| {c} | {v} |")

lines.append("\n## 3. ã‚­ãƒ¼ãƒ•ãƒ¬ãƒ¼ã‚ºä¸Šä½\n")
for term, cnt in top_terms:
    lines.append(f"- {term} ({cnt})")

if plot_ok:
    lines.append("\n## 4. ãƒã‚¸ã‚·ãƒ§ãƒ‹ãƒ³ã‚°å›³\n")
    lines.append(f"![positioning](./{os.path.basename(OUT_PNG)})\n")
else:
    lines.append("\n> å›³ã®ç”Ÿæˆã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã—ãŸï¼ˆmatplotlibæœªå°å…¥ï¼‰ã€‚`pip install matplotlib` å¾Œã«å†å®Ÿè¡Œã§ç”Ÿæˆã•ã‚Œã¾ã™ã€‚\n")

os.makedirs(os.path.dirname(OUT_MD), exist_ok=True)
with open(OUT_MD, "w", encoding="utf-8") as f:
    f.write("\n".join(lines))

print(f"âœ… qualitative_summary.md â†’ {OUT_MD}")
if plot_ok:
    print(f"âœ… positioning.png â†’ {OUT_PNG}")


===== FILE: C:\Users\MaoGon\ai_dev_core\ops\generate_reviews_sample.py =====
import csv, os
from datetime import datetime

ROOT = os.path.expanduser(os.path.join("~","Projects","ai_dev_core"))
OUT  = os.path.join(ROOT, "docs", "research", "market", "reviews_sample.csv")

rows = [
    # app_name, rating(1-5), text
    ["SnapMuse AI", 5, "æ“ä½œãŒç›´æ„Ÿçš„ã§ã€æ•°åˆ†ã§å†™çœŸé›†ãŒã§ãã‚‹ã€‚è‡ªå‹•ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆãŒã¡ã‚‡ã†ã©è‰¯ã„ã€‚ã‚µãƒ–ã‚¹ã‚¯980å††ã¯å¦¥å½“ã€‚"],
    ["SnapMuse AI", 4, "é¡”ã®ä¸€è²«æ€§ã¯æ™‚ã€…å´©ã‚Œã‚‹ãŒã€SNSç”¨ã«ã¯ååˆ†ã€‚ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆãŒé€Ÿã„ã€‚"],
    ["SnapMuse AI", 3, "ç„¡æ–™ãƒˆãƒ©ã‚¤ã‚¢ãƒ«ãŒåˆ†ã‹ã‚Šã«ãã„ã€‚å¹´é–“ãƒ—ãƒ©ãƒ³ã®å‰²å¼•ã¯é­…åŠ›ã€‚UXã¯æ”¹å–„ä½™åœ°ã‚ã‚Šã€‚"],
    ["SnapMuse AI", 2, "ç´°ã‹ã„é…ç½®èª¿æ•´ãŒã§ããªã„ã€‚ãƒ˜ãƒ«ãƒ—ãŒè–„ã„ã€‚è¿”é‡‘å¯¾å¿œã¯æ—©ã‹ã£ãŸã€‚"],
    ["SnapMuse AI", 5, "å’Œæ–‡ãƒ•ã‚©ãƒ³ãƒˆã‚‚ç¶ºéº—ã§ã€å°åˆ·ã‚¯ã‚ªãƒªãƒ†ã‚£ã‚‚è‰¯ã„ã€‚å®¶æ—ã‚¢ãƒ«ãƒãƒ ã«æœ€é©ã€‚"],

    ["PixStory Pro", 4, "ãƒ†ãƒ³ãƒ—ãƒ¬ãŒè±Šå¯Œã§æ¥½ã€‚æœˆé¡1200å††ã¯å°‘ã—é«˜ã‚ã ãŒå“è³ªã¯è‰¯ã„ã€‚"],
    ["PixStory Pro", 5, "é¡”èªè­˜ãŒå¼·ã„ã€‚ä¸€è²«æ€§ãŒé«˜ããƒ¢ãƒ‡ãƒ«æ’®å½±ã£ã½ãä»•ä¸ŠãŒã‚‹ã€‚SNSæ˜ ãˆã™ã‚‹ã€‚"],
    ["PixStory Pro", 3, "æ›¸ãå‡ºã—ã«æ™‚é–“ãŒã‹ã‹ã‚‹ã€‚UIã®åå¿œãŒé…ã„ã¨ããŒã‚ã‚‹ã€‚"],
    ["PixStory Pro", 2, "èª²é‡‘å°ç·šãŒå¼·ã™ãã¦ä¸å¿«ã€‚ãŠè©¦ã—ãŒçŸ­ã„ã€‚"],
    ["PixStory Pro", 4, "ã‚³ãƒ©ãƒ¼ã‚¸ãƒ¥æ©Ÿèƒ½ãŒä¾¿åˆ©ã€‚ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ãŒä¸å¯§ã§è¿·ã‚ãªã„ã€‚"],

    ["PhotoVerse", 5, "å¹´é¡ãƒ—ãƒ©ãƒ³ã®å‰²å¼•ãŒå¤§ãã„ã€‚å®¶æ—ã‚¤ãƒ™ãƒ³ãƒˆã¾ã¨ã‚ã«é‡å®ã€‚"],
    ["PhotoVerse", 4, "ä¾¡æ ¼ã¯æ‰‹é ƒï¼ˆ780å††ï¼‰ã€‚ãƒ•ã‚£ãƒ«ã‚¿ã‚‚è±Šå¯Œã§éŠã¹ã‚‹ã€‚"],
    ["PhotoVerse", 2, "äººç‰©ã®æ‰‹ãŒå´©ã‚Œã‚‹ã“ã¨ãŒå¤šã„ã€‚ã‚µãƒãƒ¼ãƒˆè¿”ç­”ãŒé…ã‹ã£ãŸã€‚"],
    ["PhotoVerse", 3, "ä½¿ã„æ–¹ãŒæœ€åˆé›£ã—ã„ã€‚æ…£ã‚Œã‚‹ã¨æ—©ã„ã€‚"],
    ["PhotoVerse", 4, "SNSãƒ—ãƒªã‚»ãƒƒãƒˆãŒè‰¯ã„ã€‚æ›¸ãå‡ºã—ã‚µã‚¤ã‚ºã®é¸æŠè‚¢ãŒå¤šã„ã€‚"],
]

os.makedirs(os.path.dirname(OUT), exist_ok=True)
with open(OUT, "w", newline="", encoding="utf-8") as f:
    w = csv.writer(f)
    w.writerow(["app_name","rating","text"])
    w.writerows(rows)

print(f"âœ… reviews_sample.csv generated â†’ {OUT}")


===== FILE: C:\Users\MaoGon\ai_dev_core\ops\test_weasyprint.py =====
from weasyprint import HTML
from weasyprint.text.fonts import FontConfiguration
import datetime, os

ROOT = os.path.expanduser("~/Projects/ai_dev_core/outputs")
os.makedirs(ROOT, exist_ok=True)

html_file = os.path.join(ROOT, "sample.html")
pdf_file = os.path.join(ROOT, "sample.pdf")

# HTMLä½œæˆ
with open(html_file, "w", encoding="utf-8") as f:
    f.write(f"""
    <html><head><meta charset='utf-8'><title>PDF Test</title></head>
    <body style='font-family:sans-serif;padding:40px;'>
      <h1>âœ… WeasyPrint PDFãƒ†ã‚¹ãƒˆ</h1>
      <p>ç”Ÿæˆæ—¥æ™‚: {datetime.datetime.now():%Y-%m-%d %H:%M:%S}</p>
      <p>GTKãƒ»Pangoãƒ»FontConfigçµ±åˆç¢ºèªã€‚</p>
    </body></html>
    """)

# PDFç”Ÿæˆ
font_config = FontConfiguration()
HTML(html_file).write_pdf(pdf_file, font_config=font_config)

print(f"âœ… PDFç”ŸæˆæˆåŠŸ: {pdf_file}")


===== FILE: C:\Users\MaoGon\ai_dev_core\ops\scripts\generate_i18n_visual.py =====
# -*- coding: utf-8 -*-
'''
generate_i18n_visual.py
LP Heroã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®è‹±æ—¥å¯¾å¿œãƒ»ç”»åƒç”Ÿæˆ
'''

from pathlib import Path
import json
from PIL import Image, ImageDraw, ImageFont

# Windowsã®ãƒãƒƒã‚¯ã‚¹ãƒ©ãƒƒã‚·ãƒ¥èª¤èªé˜²æ­¢
root = Path.home() / 'Projects' / 'ai_dev_core'
img_dir = root / 'docs' / 'product' / 'img'
i18n_dir = root / 'docs' / 'product' / 'i18n'
adr_dir = root / 'docs' / 'ADR'
img_dir.mkdir(parents=True, exist_ok=True)
i18n_dir.mkdir(parents=True, exist_ok=True)

# === è‹±æ—¥å¯¾è¨³å®šç¾© ===
i18n = {
    'EmotionCut': {
        'ja': {'title': 'EmotionCut', 'subtitle': 'æ„Ÿæƒ…ãƒˆãƒªã‚¬ãƒ¼ã§åˆ‡ã‚ŠæŠœããŒ1åˆ†ã§å®Œæˆ'},
        'en': {'title': 'EmotionCut', 'subtitle': 'Cut your highlights in 1 minute with emotion triggers'}
    },
    'TrendHook': {
        'ja': {'title': 'TrendHook', 'subtitle': 'ä»Šã€åˆºã•ã‚‹æŠ•ç¨¿ã‚’AIãŒææ¡ˆ'},
        'en': {'title': 'TrendHook', 'subtitle': 'AI suggests posts that hit the trend right now'}
    }
}

def make_hero(title: str, subtitle: str, filename: str):
    w, h = 1200, 675
    img = Image.new('RGB', (w, h), (25, 27, 35))
    draw = ImageDraw.Draw(img)
    try:
        font_title = ImageFont.truetype('arial.ttf', 70)
        font_sub = ImageFont.truetype('arial.ttf', 36)
    except:
        font_title = ImageFont.load_default()
        font_sub = ImageFont.load_default()
    draw.text((80, 200), title, fill=(255, 255, 255), font=font_title)
    draw.text((80, 300), subtitle, fill=(180, 180, 200), font=font_sub)
    img.save(img_dir / filename, quality=95)
    print(f'âœ… Hero image generated: {filename}')

# === Heroç”»åƒè‹±æ—¥ç”Ÿæˆ ===
for app, langs in i18n.items():
    for lang, data in langs.items():
        fname = f'hero_{app.lower()}_{lang}.jpg'
        make_hero(data['title'], data['subtitle'], fname)

# === JSONä¿å­˜ ===
json_path = i18n_dir / 'hero_i18n_map.json'
json_path.write_text(json.dumps(i18n, ensure_ascii=False, indent=2), encoding='utf-8')
print(f'âœ… JSON written: {json_path.name}')

# === ADRç”Ÿæˆ ===
adr_text = (
    "# ADR-0003: LPå¤šè¨€èªåŒ–ã¨Heroç”»åƒç”Ÿæˆæ–¹é‡\n\n"
    "## èƒŒæ™¯\n"
    "- LPã®å›½éš›å±•é–‹ã‚’è¦‹æ®ãˆã€Heroãƒ†ã‚­ã‚¹ãƒˆãƒ»ç”»åƒã®è‹±æ—¥2è¨€èªå±•é–‹ã‚’æ¨™æº–åŒ–ã€‚\n"
    "- ä»Šå¾Œã€image_genã‚’æ´»ç”¨ã—è‡ªå‹•ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«å·®åˆ†ï¼ˆA/Bãƒ†ã‚¹ãƒˆï¼‰ã‚’è¡Œã†ã€‚\n\n"
    "## æ±ºå®š\n"
    "- Heroæ§‹æˆè¦ç´ ï¼ˆã‚¿ã‚¤ãƒˆãƒ«ãƒ»ã‚µãƒ–ã‚¿ã‚¤ãƒˆãƒ«ï¼‰ã‚’JSONã§ç®¡ç†ã€‚\n"
    "- Pythonã‚¹ã‚¯ãƒªãƒ—ãƒˆ generate_i18n_visual.py ã«ã‚ˆã‚ŠHeroç”»åƒã‚’è‹±æ—¥ä¸¡æ–¹è‡ªå‹•ç”Ÿæˆã€‚\n"
    "- å‡ºåŠ›å…ˆ:\n"
    "  - /docs/product/img/hero_<app>_<lang>.jpg\n"
    "  - /docs/product/i18n/hero_i18n_map.json\n\n"
    "## å®Ÿè¡Œæ‰‹é †\n"
    "PowerShell:\n"
    "    cd $HOME/Projects/ai_dev_core\n"
    "    python ops/scripts/generate_i18n_visual.py\n\n"
    "## ä»Šå¾Œã®å±•é–‹\n"
    "- image_genãƒ„ãƒ¼ãƒ«ã§ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«å·®åˆ†ã‚’è‡ªå‹•ç”Ÿæˆã—ã€A/Bãƒ†ã‚¹ãƒˆæŒ‡æ¨™ï¼ˆCTRãƒ»CVRï¼‰ã‚’è¨˜éŒ²ã€‚\n"
    "- ç¿»è¨³ã¯å›ºå®šæ–‡å‹ã‹ã‚‰LLMå‡ºåŠ›è£œåŠ©ã¸ç§»è¡Œå¯èƒ½ã€‚\n"
)
adr_path = adr_dir / 'ADR-0003_i18n_visual.md'
adr_path.write_text(adr_text, encoding='utf-8')
print(f'âœ… ADR document created: {adr_path.name}')

print('ğŸ¯ Heroå¤šè¨€èªå±•é–‹ã¨ç”»åƒç”ŸæˆãŒå®Œäº†ã—ã¾ã—ãŸã€‚')


===== FILE: C:\Users\MaoGon\ai_dev_core\ops\scripts\generate_lp_mock.py =====
# -*- coding: utf-8 -*-
"""
generate_lp_mock.py
EmotionCut / TrendHook ã® LPç”¨ Heroç”»åƒã¨ãƒ¢ãƒƒã‚¯æ§‹æˆã‚’ç”Ÿæˆ
"""

from pathlib import Path
from PIL import Image, ImageDraw, ImageFont

root = Path.home() / "Projects/ai_dev_core"
img_dir = root / "docs/product/img"
mock_dir = root / "docs/product/mock"
img_dir.mkdir(parents=True, exist_ok=True)
mock_dir.mkdir(parents=True, exist_ok=True)

def make_hero(title: str, subtitle: str, filename: str):
    w, h = 1200, 675
    img = Image.new("RGB", (w, h), (18, 22, 33))
    draw = ImageDraw.Draw(img)
    try:
        font_title = ImageFont.truetype("arial.ttf", 70)
        font_sub = ImageFont.truetype("arial.ttf", 36)
    except:
        font_title = ImageFont.load_default()
        font_sub = ImageFont.load_default()
    draw.text((80, 200), title, fill=(255, 255, 255), font=font_title)
    draw.text((80, 300), subtitle, fill=(180, 180, 200), font=font_sub)
    img.save(img_dir / filename, quality=95)
    print(f"âœ… Hero image saved: {filename}")

def make_mock_md(app: str, sections: list[str]):
    out_path = mock_dir / f"LP_{app}_mock.md"
    lines = [f"# LPæ§‹æˆãƒ¢ãƒƒã‚¯ ({app})", ""]
    for i, sec in enumerate(sections, 1):
        lines.append(f"## {i}. {sec}")
        lines.append(f"ï¼ˆã“ã“ã« {sec} ã®è¦ç´ é…ç½®äºˆå®šï¼‰")
        lines.append("")
    out_path.write_text("\n".join(lines), encoding="utf-8")
    print(f"âœ… Mock markdown saved: {out_path.name}")

# EmotionCut
make_hero("EmotionCut", "æ„Ÿæƒ…ãƒˆãƒªã‚¬ãƒ¼ã§åˆ‡ã‚ŠæŠœããŒ1åˆ†ã§å®Œæˆ", "hero_emotioncut.jpg")
make_mock_md("EmotionCut", ["Hero", "Problem", "Solution", "Demo", "Pricing", "FAQ"])

# TrendHook
make_hero("TrendHook", "ä»Šã€åˆºã•ã‚‹æŠ•ç¨¿ã‚’AIãŒææ¡ˆ", "hero_trendhook.jpg")
make_mock_md("TrendHook", ["Hero", "Problem", "Solution", "Demo", "Pricing", "FAQ"])

print("ğŸ¯ ã™ã¹ã¦ã®LPãƒ¢ãƒƒã‚¯ç”ŸæˆãŒå®Œäº†ã—ã¾ã—ãŸã€‚")


